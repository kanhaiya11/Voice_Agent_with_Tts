{"version":3,"sources":["../../src/metrics/base.ts"],"sourcesContent":["// SPDX-FileCopyrightText: 2024 LiveKit, Inc.\n//\n// SPDX-License-Identifier: Apache-2.0\n\nexport type AgentMetrics =\n  | STTMetrics\n  | LLMMetrics\n  | TTSMetrics\n  | VADMetrics\n  | EOUMetrics\n  | RealtimeModelMetrics;\n\nexport type LLMMetrics = {\n  type: 'llm_metrics';\n  label: string;\n  requestId: string;\n  timestamp: number;\n  duration: number;\n  ttft: number;\n  cancelled: boolean;\n  completionTokens: number;\n  promptTokens: number;\n  promptCachedTokens: number;\n  totalTokens: number;\n  tokensPerSecond: number;\n  speechId?: string;\n};\n\nexport type STTMetrics = {\n  type: 'stt_metrics';\n  label: string;\n  requestId: string;\n  timestamp: number;\n  /**\n   * The request duration in seconds, 0.0 if the STT is streaming.\n   */\n  duration: number;\n  /**\n   * The duration of the pushed audio in seconds.\n   */\n  audioDuration: number;\n  /**\n   * Whether the STT is streaming (e.g using websocket).\n   */\n  streamed: boolean;\n};\n\nexport type TTSMetrics = {\n  type: 'tts_metrics';\n  label: string;\n  requestId: string;\n  timestamp: number;\n  ttfb: number;\n  duration: number;\n  audioDuration: number;\n  cancelled: boolean;\n  charactersCount: number;\n  streamed: boolean;\n  segmentId?: string;\n  speechId?: string;\n};\n\nexport type VADMetrics = {\n  type: 'vad_metrics';\n  label: string;\n  timestamp: number;\n  idleTime: number;\n  inferenceDurationTotal: number;\n  inferenceCount: number;\n};\n\nexport type EOUMetrics = {\n  type: 'eou_metrics';\n  timestamp: number;\n  /**\n   * Amount of time between the end of speech from VAD and the decision to end the user's turn.\n   * Set to 0.0 if the end of speech was not detected.\n   */\n  endOfUtteranceDelay: number;\n  /**\n   * Time taken to obtain the transcript after the end of the user's speech.\n   * Set to 0.0 if the end of speech was not detected.\n   */\n  transcriptionDelay: number;\n  /**\n   * Time taken to invoke the user's `Agent.onUserTurnCompleted` callback.\n   */\n  onUserTurnCompletedDelay: number;\n  speechId?: string;\n};\n\nexport type RealtimeModelMetricsCachedTokenDetails = {\n  audioTokens: number;\n  textTokens: number;\n  imageTokens: number;\n};\n\nexport type RealtimeModelMetricsInputTokenDetails = {\n  audioTokens: number;\n  textTokens: number;\n  imageTokens: number;\n  cachedTokens: number;\n  cachedTokensDetails?: RealtimeModelMetricsCachedTokenDetails;\n};\n\nexport type RealtimeModelMetricsOutputTokenDetails = {\n  textTokens: number;\n  audioTokens: number;\n  imageTokens: number;\n};\n\nexport type RealtimeModelMetrics = {\n  type: 'realtime_model_metrics';\n  label: string;\n  requestId: string;\n  /**\n   * The timestamp of the response creation.\n   */\n  timestamp: number;\n  /**\n   * The duration of the response from created to done in seconds.\n   */\n  duration: number;\n  /**\n   * Time to first audio token in seconds. -1 if no audio token was sent.\n   */\n  ttft: number;\n  /**\n   * Whether the request was cancelled.\n   */\n  cancelled: boolean;\n  /**\n   * The number of input tokens used in the Response, including text and audio tokens.\n   */\n  inputTokens: number;\n  /**\n   * The number of output tokens sent in the Response, including text and audio tokens.\n   */\n  outputTokens: number;\n  /**\n   * The total number of tokens in the Response.\n   */\n  totalTokens: number;\n  /**\n   * The number of tokens per second.\n   */\n  tokensPerSecond: number;\n  /**\n   * Details about the input tokens used in the Response.\n   */\n  inputTokenDetails: RealtimeModelMetricsInputTokenDetails;\n  /**\n   * Details about the output tokens used in the Response.\n   */\n  outputTokenDetails: RealtimeModelMetricsOutputTokenDetails;\n};\n"],"mappings":";;;;;;;;;;;;;;AAAA;AAAA;","names":[]}