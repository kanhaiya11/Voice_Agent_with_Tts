import { FfiClient } from "./ffi_client.js";
import { FfiHandle } from "./napi/native.js";
import {
  AudioSourceType,
  CaptureAudioFrameRequest,
  ClearAudioBufferRequest,
  NewAudioSourceRequest
} from "./proto/audio_frame_pb.js";
class AudioSource {
  constructor(sampleRate, numChannels, queueSize = 1e3) {
    /** @internal */
    this.release = () => {
    };
    this.promise = this.newPromise();
    /** @internal */
    this.timeout = void 0;
    /** @internal */
    this.closed = false;
    this.sampleRate = sampleRate;
    this.numChannels = numChannels;
    this.queueSize = queueSize;
    this.lastCapture = 0;
    this.currentQueueSize = 0;
    const req = new NewAudioSourceRequest({
      type: AudioSourceType.AUDIO_SOURCE_NATIVE,
      sampleRate,
      numChannels,
      queueSizeMs: queueSize
    });
    const res = FfiClient.instance.request({
      message: {
        case: "newAudioSource",
        value: req
      }
    });
    this.info = res.source.info;
    this.ffiHandle = new FfiHandle(res.source.handle.id);
  }
  get queuedDuration() {
    return Math.max(
      this.currentQueueSize - Number(process.hrtime.bigint() / BigInt(1e6)) + this.lastCapture,
      0
    );
  }
  clearQueue() {
    const req = new ClearAudioBufferRequest({
      sourceHandle: this.ffiHandle.handle
    });
    FfiClient.instance.request({
      message: {
        case: "clearAudioBuffer",
        value: req
      }
    });
    this.currentQueueSize = 0;
    this.release();
  }
  /** @internal */
  async newPromise() {
    return new Promise((resolve) => {
      this.release = resolve;
    });
  }
  async waitForPlayout() {
    return this.promise.then(() => {
      this.lastCapture = 0;
      this.currentQueueSize = 0;
      this.promise = this.newPromise();
      this.timeout = void 0;
    });
  }
  async captureFrame(frame) {
    if (this.closed) {
      throw new Error("AudioSource is closed");
    }
    if (frame.samplesPerChannel === 0) {
      return;
    }
    const now = Number(process.hrtime.bigint() / BigInt(1e6));
    const elapsed = this.lastCapture === 0 ? 0 : now - this.lastCapture;
    const frameDurationMs = frame.samplesPerChannel / frame.sampleRate * 1e3;
    this.currentQueueSize = Math.max(this.currentQueueSize - elapsed, 0) + frameDurationMs;
    this.lastCapture = now;
    if (this.timeout) {
      clearTimeout(this.timeout);
    }
    this.timeout = setTimeout(this.release, this.currentQueueSize);
    const req = new CaptureAudioFrameRequest({
      sourceHandle: this.ffiHandle.handle,
      buffer: frame.protoInfo()
    });
    const res = FfiClient.instance.request({
      message: { case: "captureAudioFrame", value: req }
    });
    const cb = await FfiClient.instance.waitFor((ev) => {
      return ev.message.case == "captureAudioFrame" && ev.message.value.asyncId == res.asyncId;
    });
    if (cb.error) {
      throw new Error(cb.error);
    }
  }
  async close() {
    this.ffiHandle.dispose();
    this.closed = true;
  }
}
export {
  AudioSource
};
//# sourceMappingURL=audio_source.js.map